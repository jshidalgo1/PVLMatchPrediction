name: Model Metrics Regression Check

on:
  push:
    branches: [main, develop]
    paths:
      - 'scripts/**'
      - 'models/**'
      - 'data/**'
      - '.github/workflows/model_metrics.yml'
  pull_request:
    branches: [main, develop]
    paths:
      - 'scripts/**'
      - 'models/**'
      - 'data/**'
      - '.github/workflows/model_metrics.yml'

jobs:
  metrics-check:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for baseline comparison
    
    - name: Set up Python 3.13
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        if [ -f outputs/requirements.txt ]; then pip install -r outputs/requirements.txt; fi
    
    - name: Train current model with player features
      run: |
        python scripts/train_xgboost_with_players.py
    
    - name: Compare metrics against baseline
      id: metrics
      run: |
        # Run comparison and capture JSON output
        python scripts/compare_metrics.py \
          models/best_model_with_players_timeaware.pkl \
          models/calibrated_xgboost_with_players.pkl
        
        # Extract latest comparison JSON and validate metrics
        python scripts/validate_metrics.py
    
    - name: Upload metrics comparison
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: metrics-comparison
        path: |
          outputs/metrics_comparison_*.json
          outputs/metrics_comparison_*.md
        retention-days: 30
    
    - name: Comment PR with metrics (if PR)
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const glob = require('glob');
          
          // Find latest markdown report
          const mdFiles = glob.sync('outputs/metrics_comparison_*.md');
          if (mdFiles.length === 0) {
            console.log('No metrics comparison found');
            return;
          }
          
          const latestMd = mdFiles.sort().reverse()[0];
          const content = fs.readFileSync(latestMd, 'utf8');
          
          // Post as PR comment
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: `## ðŸŽ¯ Model Metrics Comparison\n\n${content}`
          });
